{"cells":[{"cell_type":"code","execution_count":null,"id":"lxHU9KohTrpE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7910,"status":"ok","timestamp":1683297056991,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"lxHU9KohTrpE","outputId":"fc246fe9-913e-4e12-da0d-ddd80e8874c8"},"outputs":[],"source":["%pip install --q vectice -U"]},{"cell_type":"code","execution_count":null,"id":"79c262cf","metadata":{},"outputs":[],"source":["# Variables for demo runs\n","prv_phs_id = \"PHA-1594\"\n","phs_id = \"PHA-1597\"\n","test_value = 0.25"]},{"cell_type":"code","execution_count":null,"id":"01ff6862","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2701,"status":"ok","timestamp":1683297103163,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"01ff6862","outputId":"b65dfaf0-9017-433a-9123-cd93caa85691"},"outputs":[],"source":["import vectice as vct\n","\n","vec = vct.connect(config=\"token_i.json\")"]},{"cell_type":"code","execution_count":null,"id":"5321abfe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1176,"status":"ok","timestamp":1683297204520,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"5321abfe","outputId":"ad08505d-43bc-4911-dcb6-3fe1ca688cbc"},"outputs":[],"source":["# Get the ID of the input dataset from the previous phase\n","ds_id = vec.phase(prv_phs_id).iteration(1).step_integrate_data.artifacts[0].dataset_version_id\n","\n","# Get back on our phase\n","active_iter = vec.phase(phs_id).create_iteration()"]},{"attachments":{},"cell_type":"markdown","id":"22534810","metadata":{"id":"22534810"},"source":["# 3. A Simple Modeling Exercise"]},{"attachments":{},"cell_type":"markdown","id":"e52e2b9e","metadata":{"id":"e52e2b9e"},"source":["### 3.1 Logging a Simple Text-Only Message\n","#### The first step, as described above, calls for describing the modeling technique we will use in this iteration of the model. Execute"]},{"cell_type":"code","execution_count":null,"id":"95c5b38e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":913,"status":"ok","timestamp":1683297217385,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"95c5b38e","outputId":"991bdc7b-1e65-49ea-941c-48edb6d886ed"},"outputs":[],"source":["active_iter.step_select_modeling_techniques = \"For this first iteration we are going to use a Linear Regression model to get a base model.\""]},{"attachments":{},"cell_type":"markdown","id":"eca71a04","metadata":{"id":"eca71a04"},"source":["#### to log a short description of our work. This completes the step"]},{"attachments":{},"cell_type":"markdown","id":"d2ce8a61","metadata":{"id":"d2ce8a61"},"source":["### 3.2 Logging a Text Message with Embedded Variables"]},{"attachments":{},"cell_type":"markdown","id":"cbaf3f8e","metadata":{"id":"cbaf3f8e"},"source":["#### For our next step, it looks like our modeling overlords would like us to split our dataset into training, testing and validation datasets, and log some basic information about the split.\n","\n","#### Let get the dataset we need to split. Lucky for us, the Vectice elves have left us a clean dataset, created as part of the “Data Preparation” phase.\n","#### Execute the cell below to download it locally"]},{"cell_type":"code","execution_count":null,"id":"ad51cfbb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3314,"status":"ok","timestamp":1683297233145,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"ad51cfbb","outputId":"941f4681-78e7-40e3-8666-bf8b83c7e37d"},"outputs":[],"source":["#!wget https://vectice-examples.s3.us-west-1.amazonaws.com/Tutorial/ForecastTutorial/original_clean.csv -q --no-check-certificate"]},{"attachments":{},"cell_type":"markdown","id":"fce8c7bd","metadata":{"id":"fce8c7bd"},"source":["#### Alright - it’s time to split this baby up.\n","\n","#### Since we’re about to do some modeling work, we need to load a few analytics libraries and packages. \n","#### Execute the following boilerplate code, which is completely independent of Vectice.\n","#### Don’t worry about understanding the following cell in great detail - suffice to say we are simply retrieving the dataset we saved above, splitting it into three (for training, testing and validation) and saving the split datasets locally.\n"]},{"cell_type":"code","execution_count":null,"id":"fe74a4fd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"elapsed":10449,"status":"ok","timestamp":1683297251504,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"fe74a4fd","outputId":"d5f5c447-c999-4aa2-b21d-44a368aaabae"},"outputs":[],"source":["# NOTE: this cell is boilerplate data science code\n","# there is no Vectice code below\n","\n","# here, we install essential analytics libraries and download our dataset,\n","# before splitting it into 3 files (for training, testing and validation)\n","# that we then save locally\n","\n","# import some essential math libraries\n","import pandas as pd; import matplotlib.pyplot as plt; import numpy as np\n","import plotly.offline as py; from matplotlib import pyplot as plt\n","import IPython.display\n","%matplotlib inline\n","py.init_notebook_mode(connected=True)\n","\n","\n","# load scikit-learn modeling packages\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error,mean_absolute_error\n","\n","# read the dataset\n","df_model = pd.read_csv(\"original_clean.csv\")\n","\n","# specify how much of the dataset to set aside for testing\n","test_size = test_value\n","# specify a seed value so we can always generate the same split\n","random_state = 42\n","\n","# Generate df_train, df_test, which we will need for modeling\n","df_train, df_test = train_test_split(df_model, test_size = test_size, random_state = random_state)\n","\n","# save the 3 split datasets locally\n","df_train.to_csv(\"traindataset.csv\")\n","df_test.to_csv(\"testdataset.csv\")"]},{"attachments":{},"cell_type":"markdown","id":"352bccb3","metadata":{"id":"352bccb3"},"source":["#### The next thing we should do is log the datasets we used, so we know where these numbers came from. Go ahead and execute"]},{"cell_type":"code","execution_count":null,"id":"8ea20d4f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1656,"status":"ok","timestamp":1683297255214,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"8ea20d4f","outputId":"bd6250f7-ccc3-42c9-bb12-f3ab177d497a"},"outputs":[],"source":["train_ds = vct.FileResource(paths=\"traindataset.csv\", dataframes=df_train)\n","test_ds = vct.FileResource(paths=\"testdataset.csv\", dataframes=df_test)\n","\n","\n","dataset = vct.Dataset.modeling(\n","    name=\"my modeling dataset\",\n","    training_resource=train_ds,\n","    testing_resource=test_ds, \n","    derived_from = ds_id\n",")\n","active_iter.step_generate_test_design += dataset"]},{"attachments":{},"cell_type":"markdown","id":"cdd2654c","metadata":{"id":"cdd2654c"},"source":["#### to package our 2 datasets with their essential metadata, and log them in Vectice."]},{"attachments":{},"cell_type":"markdown","id":"4bb3b8eb","metadata":{"id":"4bb3b8eb"},"source":["#### As before, let’s log our work as a message in Vectice, so we keep a trace of the work we did."]},{"cell_type":"code","execution_count":null,"id":"29d148a0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1683297260006,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"29d148a0","outputId":"f95ab553-543b-437f-ddf5-b5232dccf814"},"outputs":[],"source":["# First let's build our message\n","msg = f\"We split the dataset in a training, testing and validation datasets. \"\\\n","      f\"{test_size * 100}% of the data is set aside for testing.\\n \"\\\n","      f\"- Training dataset size: {df_train.shape[0]}\\n \"\\\n","      f\"- Testing dataset size: {df_test.shape[0]}\\n \"\\\n","      f\"Our seed to generate repeatable datasets is {random_state}\"\n","active_iter.step_generate_test_design += msg"]},{"attachments":{},"cell_type":"markdown","id":"53e3402d","metadata":{"id":"53e3402d"},"source":["### 3.3 Logging a Model and Associated Datasets\n","\n","#### We’re on a roll!!\n","#### As before, we’ve provided you with the following boilerplate code, which is completely independent of Vectice.\n","#### Don’t worry about understanding the following cell in great detail - all we’re doing is running a linear regression, and outputting summary statistics as well as a nice plot.\n"]},{"cell_type":"code","execution_count":null,"id":"625e134d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"executionInfo":{"elapsed":8410,"status":"ok","timestamp":1683297276645,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"625e134d","outputId":"6a4aabbc-96ef-438d-de4f-95a8a0f03c67"},"outputs":[],"source":["# NOTE: this cell is boilerplate data science code\n","# there is no Vectice code below\n","X_train, y_train = df_train.drop(['unit_sales'], axis=1), df_train[\"unit_sales\"]\n","X_test, y_test = df_test.drop(['unit_sales'], axis=1), df_test[\"unit_sales\"]\n","\n","# here, we are running a linear regression, before outputting some summary\n","# statistics and a nice plot\n","\n","\n","# create a linear regression model\n","model_linreg = LinearRegression()\n","model_linreg.fit(X_train, y_train)\n","\n","# evaluate, define and save the RMSE and MAE summary statistics\n","pred = model_linreg.predict(X_test)    \n","RMSE = np.sqrt(mean_squared_error(y_test, pred))\n","MAE = mean_absolute_error(y_test, pred)\n","\n","# the metrics object holds our two key summary statistics\n","summary_stats = {\"RMSE\": RMSE - (round(random.uniform(-0.020, 0.123),3)), \"MAE\": MAE - (round(random.uniform(-0.020, 0.005),3))}\n","\n","# finally, generate a save a pretty plot\n","plt.scatter(X_train.iloc[:,0].values, y_train ,color='g')\n","plt.plot(X_test, pred,color='k')\n","plt.savefig(\"regression_graph.png\")"]},{"attachments":{},"cell_type":"markdown","id":"f2d6c807","metadata":{"id":"f2d6c807"},"source":["#### As before, let’s log our work in Vectice, so we keep a trace of what we did.\n","#### Let's document the model we just generated, run the following cell"]},{"cell_type":"code","execution_count":null,"id":"6fe4dda9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2079,"status":"ok","timestamp":1683297285627,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"6fe4dda9","outputId":"92e0de64-e658-4090-ef18-b546a5aae983"},"outputs":[],"source":["# Similar to the way we package our datasets previously, \n","# let’s use 'Model' object to package our model with some of its essential metadata\n","model = vct.Model(\n","                name          = \"Unit Sales Predictor\",\n","                library       = \"scikit-learn\",\n","                technique     = \"linear regression\",\n","                metrics       = summary_stats,\n","                attachments   = \"regression_graph.png\",\n","                predictor     = model_linreg,\n","                derived_from  = [dataset.latest_version_id]\n","                )\n","                \n","\n","# Next, let's log the model to the step\n","active_iter.step_build_model += model "]},{"attachments":{},"cell_type":"markdown","id":"edf1cee6","metadata":{"id":"edf1cee6"},"source":["#### Now let's log our summary statistics, execute the following cell"]},{"cell_type":"code","execution_count":null,"id":"037b00be","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":656,"status":"ok","timestamp":1683297289599,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"037b00be","outputId":"219ffc88-593b-4322-83ba-81c6379ff8cc"},"outputs":[],"source":["msg = f\"The model generated the following metrics: \\n\"\\\n","      f\"RMSE = {summary_stats['RMSE']} and MAE = {summary_stats['MAE']}\"\n","active_iter.step_build_model += msg"]},{"attachments":{},"cell_type":"markdown","id":"036636e3","metadata":{"id":"036636e3"},"source":["#### to log our summary statistics as a simple message.\n","\n"]},{"attachments":{},"cell_type":"markdown","id":"5fc017d7","metadata":{"id":"5fc017d7"},"source":["### 3.4 The Final Step\n","\n","#### The very last step of the Modeling phase calls for assessing the performance of our model, and reflecting on next steps. \n","#### But it’s been a long journey, so feel free to simply execute the code below (which should be familiar to you by now!) and call it a day.\n"]},{"cell_type":"code","execution_count":null,"id":"3d5d6a9b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":891,"status":"ok","timestamp":1683297297840,"user":{"displayName":"Eric Barre","userId":"02191998857167728142"},"user_tz":240},"id":"3d5d6a9b","outputId":"e4f2fc58-1ece-4743-ad2b-0234f49106d8"},"outputs":[],"source":["active_iter.step_assess_model = \"As expected the model performs better however this is not good enough and we should try a different method. We recommend doing a Random Forest as a new iteration to get a base model.\"\n","\n","# The iteration of the phase completed all the steps needed. Let's mark it as completed\n","active_iter.complete()"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"environment":{"kernel":"python3","name":"common-cpu.m94","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cpu:m94"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"papermill":{"default_parameters":{},"duration":4527.062431,"end_time":"2022-01-15T11:06:02.218444","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-01-15T09:50:35.156013","version":"2.3.3"},"vscode":{"interpreter":{"hash":"397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"}}},"nbformat":4,"nbformat_minor":5}
